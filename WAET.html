<!doctype html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
<head>
    <title>Developers' Guide to Features of Web Accessibility Evaluation
        Tools</title>

    <meta charset="utf-8"/>

    <link href="https://www.w3.org/StyleSheets/TR/W3C-ED.css" rel="stylesheet"
          type="text/css"/>

    <style type="text/css">
        table {
            width: 100%;
            border-collapse: collapse;
        }

        table, tr, th, td {
            border: 1px solid #000;
        }

        abbr {
            border-bottom: dotted 1px #444;
        }

        q {
            font-style: italic;
        }

        q:before {
            content: open-quote;
        }

        q:after {
            content: close-quote;
        }

        ul.w3ctoc li {
            list-style: none;
        }

        a.termref {
            text-decoration: none;
            color: #00f;
            padding-bottom: 0;
            margin-bottom: 0;
            border-bottom: dashed #808080 1px;
            background-color: transparent;
        }

        a.termref:visited {
            color: magenta;
            background: inherit;
        }

        a.termref:hover, .termref:active, a.termref:focus {
            color: #00c;
            background: inherit;
        }

        dd, li {
            margin-top: 0.25em;
        }

        dt {
            margin-top: 0.5em;
        }

        .note {
            background-color: #ffffcc;
            border: thin dashed;
            padding: 5px;
        }
    </style>
</head>

<body>

<p style="text-align:center;">[<a href="#intro" rel="contents">contents</a>]</p>

<div class="head" id="head">

    <p>
        <a href="http://www.w3.org/"><img alt="W3C" height="48"
                                          src="https://www.w3.org/Icons/w3c_home"
                                          width="72"/></a>
    </p>

    <h1 id="title">Developers' Guide to Features of Web Accessibility Evaluation
        Tools</h1>

    <h2 id="w3c-doctype">Editors' Draft 10 October 2014</h2>
    <dl>
        <dt>This version:</dt>

        <dd><a href="http://www.w3.org/TR/2014/WD-WAET-20141010/">http://www.w3.org/TR/2014/WD-WAET-20141010/</a>
        </dd>

        <dt>Latest version:</dt>

        <dd><a href="http://www.w3.org/TR/WAET/">http://www.w3.org/TR/WAET/</a>
        </dd>

        <dt>Previous published version:</dt>

        <dd><a href="http://www.w3.org/TR/2014/WD-WAET-20140724/">http://www.w3.org/TR/2014/WD-WAET-20140724/</a>
        </dd>

        <dt>Editors:</dt>

        <dd>Carlos A Velasco, <a href="http://www.fit.fraunhofer.de/">Fraunhofer
            Institute for Applied Information Technology FIT</a></dd>

        <dd><a href="http://www.w3.org/People/shadi/">Shadi Abou-Zahra</a>, W3C
            Web Accessibility Initiative (WAI)
        </dd>
    </dl>
    <p class="copyright"><a
            href="http://www.w3.org/Consortium/Legal/ipr-notice#Copyright">Copyright</a>
        © 2014 <a href="http://www.w3.org/"><abbr
                title="World Wide Web Consortium">W3C</abbr></a><sup>®</sup> (<a
                href="http://www.csail.mit.edu/"><abbr
                title="Massachusetts Institute of Technology">MIT</abbr></a>, <a
                href="http://www.ercim.org/"><abbr
                title="European Research Consortium for Informatics and Mathematics">ERCIM</abbr></a>,
        <a href="http://www.keio.ac.jp/">Keio</a>, <a
                href="http://ev.buaa.edu.cn/">Beihang</a>), All Rights Reserved.
        <abbr title="World Wide Web Consortium">W3C</abbr> <a
                href="http://www.w3.org/Consortium/Legal/ipr-notice#Legal_Disclaimer">liability</a>,
        <a href="http://www.w3.org/Consortium/Legal/ipr-notice#W3C_Trademarks">trademark</a>
        and <a href="http://www.w3.org/Consortium/Legal/copyright-documents">document
            use</a> rules apply. </p></div>
<hr/>

<h2 id="abstract">Abstract</h2>

<p>This document describes features that quality assurance and web authoring
    tools may incorporate to support the evaluation of accessibility
    requirements, such as those defined by the <a
            href="http://www.w3.org/WAI/intro/wcag">Web Content Accessibility
        Guidelines (<abbr>WCAG</abbr>)
        2.0</a>. The main purpose of this document is to promote awareness on
    such features and to give an introductory guidance for tool developers on
    what kinds of features they could provide in future implementations of their
    tools. This list of features could also be used to help compare different
    types of evaluation tools, for example, during the procurement of such
    tools.</p>

<p>The features in scope of this document include capabilities to specify,
    manage, carry out and report the results from web accessibility evaluations.
    For example, some of the described features relate to crawling web sites,
    interacting with tool users to carry out semiautomated evaluation, or
    providing evaluation results in a machine-readable format. This document
    does not describe the evaluation of web content features, which is addressed
    by <abbr title="Web Content Accessibility Guidelines">WCAG</abbr> 2.0 and
    its supporting documents.</p>

<p>This document encourages the incorporation of accessibility evaluation
    features in all web authoring and quality assurance tools, and the continued
    development and creation of different types of web accessibility evaluation
    tools. The document neither prescribes nor prioritizes any particular
    accessibility evaluation feature or specific type of evaluation tools. It
    describes features that can be provided by tools that support
    fully-automated, semiautomated and manual web accessibility evaluation.
    Following this document can help tool developers to meet accessibility
    checking requirements defined by the <a
            href="http://www.w3.org/WAI/intro/atag">Authoring Tool Accessibility
        Guidelines (<abbr>ATAG</abbr>)</a>.</p>

<div id="sotd">

    <h2 id="status">Status of this document</h2>

    <p><em>This section describes the status of this document at the time of its
        publication. Other documents may supersede this document. A list of
        current <abbr>W3C</abbr> publications and the latest revision of this
        technical report can be found in the <a
                href="http://www.w3.org/TR/"><abbr>W3C</abbr> technical reports
            index</a> at http://www.w3.org/TR/.</em></p>

    <p>This 24 July 2014 First Public Working Draft of Developers' Guide to
        Features of Web Accessibility Evaluation Tools is intended to be
        published and maintained as a <abbr>W3C</abbr> Working Group Note after
        review and refinement. It provides an initial outline for the format and
        approach taken in this document to gather early feedback on it. Some
        features may be missing in this first iteration of the document.
        Suggestions for additional features to be listed in this document is
        welcome.</p>

    <p>The <a href="http://www.w3.org/WAI/ER/">Evaluation and Repair Tools
        Working Group (<abbr>ERT WG</abbr>)</a> invites discussion and feedback
        on this document by web accessibility evaluation tool developers, web
        authoring and quality assurance tool developers, evaluators,
        researchers, and others with interest in web accessibility evaluation
        tools. In particular, <abbr>ERT WG</abbr> is looking for feedback on:
    </p>
    <ul>
        <li>The format and approach taken in this document;</li>

        <li>Features descriptions that are currently missing;</li>

        <li>Feedback on the included feature descriptions.</li>
    </ul>
    <p>Please send comments on this Developers' Guide to Features of Web
        Accessibility Evaluation Tools document by 15 August 2014 to <a
                href="mailto:public-wai-ert-tools@w3.org">public-wai-ert-tools@w3.org</a>
        (publicly visible <a
                href="http://lists.w3.org/Archives/Public/public-wai-ert-tools/">mailing
            list archive</a>).</p>

    <p>Publication as a First Public Working Draft does not imply endorsement by
        the <abbr>W3C</abbr> Membership. This is a draft document and may be
        updated, replaced or obsoleted by other documents at any time. It is
        inappropriate to cite this document as other than work in progress.</p>

    <p>This document has been produced by the <a
            href="http://www.w3.org/WAI/ER/">Evaluation and Repair Tools Working
        Group (ERT WG)</a>, as part of the <a
            href="http://www.w3.org/WAI/Technical/Activity">Web Accessibility
        Initiative (WAI) Technical Activity</a>.</p>

    <p>This document was produced by a group operating under the <a
            href="http://www.w3.org/Consortium/Patent-Policy-20040205/">5
        February 2004 <abbr>W3C</abbr> Patent Policy</a>. The group does not
        expect this document to become a <abbr>W3C</abbr> Recommendation. <abbr>W3C</abbr>
        maintains a <a href="http://www.w3.org/2004/01/pp-impl/32094/status"
                       rel="disclosure">public list of any patent
            disclosures</a> made in connection with the deliverables of the
        group; that page also includes instructions for disclosing a patent. An
        individual who has actual knowledge of a patent which the individual
        believes contains <a
                href="http://www.w3.org/Consortium/Patent-Policy-20040205/#def-essential">Essential
            Claim(s)</a> must disclose the information in accordance with <a
                href="http://www.w3.org/Consortium/Patent-Policy-20040205/#sec-Disclosure">section
            6 of the <abbr>W3C</abbr> Patent Policy</a>.</p>
</div>

<hr/>

<h2 id="contents">Table of Contents</h2>

<ul class="w3ctoc">
    <li><a href="#abstract">Abstract</a></li>

    <li><a href="#status">Status of this document</a></li>

    <li><a href="#contents">Table of Contents</a></li>

    <li><a href="#intro">1 Introduction</a>
        <ul>
            <li><a href="#tools">1.1 Evaluation Tools</a></li>
        </ul>
    </li>

    <li><a href="#features">2 Features of an accessibility evaluation tool</a>
        <ul>
            <li><a href="#subjects">2.1 Retrieving and rendering web content</a>
                <ul>
                    <li><a href="#resformats">2.1.1 Resource formats</a></li>

                    <li><a href="#charencoding">2.1.2 Character encodings</a></li>

                    <li><a href="#clanguage">2.1.3 Content language</a></li>

                    <li><a href="#fragments">2.1.4 <abbr>DOM</abbr> Document
                        fragments</a></li>

                    <li><a href="#renderedDOM">2.1.5 Static code evaluation vs.
                        rendered DOM evaluation</a></li>

                    <li><a href="#cnegotiation">2.1.6 Content negotiation</a>
                    </li>

                    <li><a href="#cookies">2.1.7 Cookies</a></li>

                    <li><a href="#authentication">2.1.8 Authentication</a></li>

                    <li><a href="#session">2.1.9 Session tracking </a></li>

                    <li><a href="#crawling">2.1.10 Crawling</a></li>

                    <li><a href="#sampling">2.1.11 Sampling</a></li>
                </ul>
            </li>

            <li><a href="#testcustom">2.2 Testing functionality</a>
                <ul>
                    <li><a href="#filterTests">2.2.1 Selection of evaluation
                        tests</a></li>

                    <li><a href="#manual">2.2.2 Test modes</a></li>

                    <li><a href="#accReqs">2.2.3 Documenting implementation of
                        accessibility requirements</a></li>

                    <li><a href="#ownTests">2.2.4 Development of own tests and
                        test extensions</a></li>

                    <li><a href="#webdriver">2.2.5 User interaction and test
                        automation</a></li>

                    <li><a href="#emulation">2.2.6 Emulating how people with
                        disabilities experience the web</a></li>
                </ul>
            </li>

            <li><a href="#reporting">2.3 Reporting and monitoring </a>
                <ul>
                    <li><a href="#stdRep">2.3.1 Machine-readable reporting
                        formats</a></li>

                    <li><a href="#database">2.3.2 Human-readable reports</a>
                    </li>

                    <li><a href="#database">2.3.3 Persistence of results</a>
                    </li>

                    <li><a href="#import">2.3.4 Importing evaluation results</a>
                    </li>

                    <li><a href="#customReport">2.3.5 Report customization</a>
                    </li>

                    <li><a href="#aggregation">2.3.6 Results aggregation</a>
                    </li>

                    <li><a href="#conformance">2.3.7 Conformance</a></li>

                    <li><a href="#repair">2.3.8 Error repair guidance</a></li>
                </ul>
            </li>

            <li><a href="#toolUsage">2.4 Tool usage</a>
                <ul>
                    <li><a href="#workflow">2.4.1 Workflow integration</a></li>

                    <li><a href="#localization">2.4.2 Localization and
                        internationalization</a></li>

                    <li><a href="#customAudience">2.4.3 Functionality
                        customization to different audiences</a></li>

                    <li><a href="#policy">2.4.4 Policy environments</a></li>

                    <li><a href="#toolAccess">2.4.5 Tool accessibility</a></li>

                    <li><a href="#platform">2.4.6 Platform</a></li>
                </ul>
            </li>
        </ul>
    </li>

    <li><a href="#profiles">3 Example profiles of evaluation tools</a>
        <ul>
            <li><a href="#plugin">3.1 Example Tool A: Browser plug-in evaluating
                a rendered HTML page</a></li>

            <li><a href="#largeScale">3.2 Example Tool B: Large-scale
                accessibility evaluation tool</a></li>

            <li><a href="#mobile">3.3 Example Tool C: Accessibility evaluation
                tool for mobile applications</a></li>

            <li><a href="#overview">3.4 Side-by-Side Comparison of the Example
                Tools</a></li>
        </ul>
    </li>

    <li><a href="#references">4 References</a></li>

    <li><a href="#ack">Acknowledgements</a></li>
</ul>
<hr/>
<h2 id="intro">1 Introduction</h2>

<p>Designing, developing, monitoring, and managing a website typically involves
    a variety of tasks and people who use different types of tools. For example,
    a web developer might use an integrated development environment
    (<abbr>IDE</abbr>) to create templates for a content management system
    (<abbr>CMS</abbr>), while a web content author will typically use the
    content-editing facility provided by the <abbr>CMS</abbr> to create and edit
    the web pages. Ideally all these tools should provide features to support
    everyone involved throughout the process of evaluating accessibility. For
    example, an <abbr>IDE</abbr> could provide functionality to check document
    fragments so that the developer can test individual web page components
    during their development, and a <abbr>CMS</abbr> could provide functionality
    to customize the accessibility checks that are automatically carried out to
    help monitor the quality of the website. This document lists and describes
    the types of features that can be provided by tools to support accessibility
    evaluation in a variety of situations and contexts.</p>

<h3 id="tools">1.1 Evaluation Tools</h3>

<p>In the context of this document, an <strong id="evaltool_def">evaluation
    tool</strong> is a (web-based or non-web-based) software application that
    enables its users to evaluate web content according to specific quality
    criteria, such as web accessibility requirements. This includes but is not
    limited to the following (non-mutually-exclusive) types of tools:</p>

<ul>
    <li id="qatool_def"><strong>Web quality assurance tool</strong> - Any
        (web-based or non-web-based) software application that is specifically
        designed to evaluate web content according to quality criteria (which
        may be broader than accessibility requirements alone);
    </li>

    <li id="a11ytool_def"><strong>Web accessibility evaluation tool</strong> -
        Any (web-based or non-web-based) software application that is
        specifically designed to evaluate web content according to accessibility
        requirements, such as the <a href="http://www.w3.org/WAI/intro/wcag">Web
            Content Accessibility Guidelines (<abbr>WCAG</abbr>) 2.0</a>;
    </li>

    <li id="authoringtool_def"><strong>Web authoring tool </strong> - <q>Any
        web-based or non-web-based application(s) that can be used by authors
        (alone or collaboratively) to create or modify web content for use by
        other people (other authors or end users)</q> and which provides an
        evaluation functionality (<cite><a
                href="http://www.w3.org/TR/ATAG20/#def-Authoring-Tool">Authoring
            Tool Accessibility Guidelines 2.0</a></cite>).
    </li>
</ul>
<p>Note that these terms are not mutually exclusive. A web accessibility
    evaluation tool is a particular type of web quality assurance tool. In other
    cases an evaluation tool could be considered to be a web authoring tool, for
    example, if it provides repair functionality that modifies the content.
    Also, a web quality assurance tool might not check for accessibility
    criteria but might provide other functionality, such as managing quality
    assurance processes and reporting evaluation results, which may be useful
    for web accessibility evaluation. This document refers to any of these tools
    collectively as evaluation tools.</p>

<p><abbr title="World Wide Web Consortium">W3C</abbr> Web Accessibility
    Initiative (<abbr>WAI</abbr>) provides a <a
            href="http://www.w3.org/WAI/ER/tools/">list of web accessibility
        evaluation tools</a> that can be searched according to different
    criteria such as the features listed in this document.</p>

<h2 id="features">2 Features of an accessibility evaluation tool</h2>

<p>The features of an accessibility evaluation tool are presented in this
    section from different perspectives: the <strong>resource to be
        evaluated</strong> (i.e., web content and its linked resources, which
    enable its rendering in the user agent), <strong>the evaluation
        requirements</strong>, the <strong>reporting customization capabilities
        of the tool</strong> and other <strong>tool usage</strong>
    characteristics like the integration into the development and editing
    workflow of the user.</p>

<p>The list of accessibility evaluation features described below is not
    exhaustive. It may be neither possible nor desired for a single tool to
    implement all of the listed features. For example, tools that are
    specifically designed to assist designers in creating web page layouts would
    likely not incorporate features for evaluating the code of web applications.
    As mentioned in the abstract, the features presented in this section are
    provided as a reference. This document does not prescribe any of them to
    developers of accessibility evaluation tools. Developers can use this list
    to identify features that are relevant to their tools to plan their
    implementation. Also others interested in acquiring and using evaluation
    tools can use this document to learn about relevant features to look
    for.</p>

<h3 id="subjects">2.1 Retrieving and rendering web content</h3>

<p>This category includes features that help to retrieve and render different
    types of web content. There are tools that may retrieve the content to be
    analyzed from the file system or from a database. However, the majority of
    them do it via a network connection through the <abbr>HTTP(S)</abbr>
    protocol. This section focuses mostly on this latter scenario. </p>

<p>Due to the characteristics of the <abbr>HTTP(S)</abbr> protocol, the
    rendering of a web resource implies the manipulation and storage of many
    other components associated with it, like request and response headers,
    session information, cookies, authentication information, etc. These
    associated components are also considered in the following. </p>

<h4 id="resformats">2.1.1 Resource formats</h4>

<p>Although the majority of web resources are <abbr>HTML</abbr> documents, there
    are many other types of resources that need to be considered when analyzing
    web accessibility. For example, resources like <abbr>CSS</abbr> stylesheets
    or JavaScript scripts allow the modification of markup documents in the user
    agent when they are loaded or via user interaction. Many accessibility tests
    are the result of the interpretation of those resources and their
    combinations, and are therefore important for an accessibility evaluation.
    Accessibility evaluation tools should state which types of resource formats
    they support.</p>

<p>The most common resource formats include:</p>

<ul>
    <li><strong>Markup formats</strong>. These are normally <abbr>HTML</abbr>
        [<a href="#HTML4">HTML4</a>, <a href="#HTML5">HTML5</a>],
        <abbr>XHTML</abbr> [<a href="#XHTML10">XHTML10</a>] or <abbr>XML</abbr>
        [<a href="#XML10">XML10</a>, <a href="#XML11">XML11</a>]
        documents. Processing these resources typically
        requires the ability to ability to render their content according to
        the Document Object (<abbr>DOM</abbr>) [<a href="#DOM">DOM</a>],
        including all associated resources, such as styles (<abbr>CSS</abbr>),
        scripts (JavaScript), media and others. Note that the particular version
        ("Level") of the <abbr>DOM</abbr> has significant impact on the
        rendering, and is relevant to consider it as part of this feature.
        <ul>
            <li><strong>Style formats</strong>. These are presentation
                modifiers, which conform to the different <abbr>CSS</abbr>
                specifications [<a href="#CSS2">CSS2</a>, <a
                        href="#CSS3">CSS3</a>].
            </li>
            <li><strong>Script formats</strong>. These are components that
                modify the content, the presentation, or the behavior of web
                resources and web applications, be it because of end-user
                interaction or because of other functional requirements (e.g.,
                notifications, dynamic updates, etc.). These resources play a
                critical role in Rich Internet Applications. Ignoring these
                resources may lead to missing accessibility problems or to
                report non-existing errors. The scripting language commonly used
                on the web is JavaScript, based upon ECMAScript [<a
                        href="#ECMAScript">ECMAScript</a>] standardized by the
                <a href="http://www.ecma-international.org/">Ecma
                    International</a> standards organization.
            </li>
        </ul>
    </li>

    <li><strong>Media formats</strong>. These are images (static or animated),
        movies or audio tracks, which are standalone or embedded within another
        web resource. It must be highlighted that media resources may be
        presented in different ways and consist of several resources, for
        example, a media track and its <a
                href="http://www.w3.org/TR/WCAG20/#captionsdef">captions</a> and
        <a href="http://www.w3.org/TR/WCAG20/#audiodescdef">audio
            descriptions</a>. From the accessibility standpoint, the evaluation
        of media resources is relevant to some evaluation requirements, such as
        ensuring that there is an adequate <a
                href="http://www.w3.org/TR/WCAG20/#contrast-ratiodef">contrast
            ratio</a> between foreground and background colors in a given image.
        There are few tools known to test automatically accessibility of media
        resources. This opens a new area of research to analyze such resources
        with machine learning algorithms, for instance.
    </li>

    <li><strong>Document formats</strong>. Many reports and administrative
        information are available in document formats, typically in government
        web sites. The format most commonly found is <abbr>PDF</abbr>, initially
        developed by Adobe [<a href="#PDF">PDF</a>] and later on standardised by
        <abbr>ISO</abbr>. Although not very frequent on the web, it is possible
        to encounter other formats as well, like the Open Document Format [<a
                href="#ODF">ODF</a>] or Microsoft Office formats [<a
                href="#OOXML">OOXML</a>].
    </li>

    <li><strong>Resources with other formats</strong>. Examples of these are <a
            href="http://www.adobe.com/products/flash.html">Adobe Flash
            movies or applications</a>, <a
            href="http://www.java.com/">Java applets</a>, <a
            href="http://www.microsoft.com/silverlight/">Microsoft
        Silverlight applications</a>, etc. These resources are normally found embedded within
        <abbr>HTML</abbr> pages as applications.
    </li>
</ul>

<h4 id="charencoding">2.1.2 Character encodings</h4>

<p>This feature identifies which character encodings are supported by the
    evaluation tool. Web content can be transmitted using different character
    encodings and sets. The correct rendering of web resources for their
    evaluation depends upon the correct interpretation of these encodings. With
    <abbr>HTML5</abbr> [<a href="#HTML5">HTML5</a>] there is a push to use UTF-8
    as the default encoding and abandon other legacy encodings. However, it is
    recommended that evaluation tools offer support for other legacy encodings.
</p>

<p>More information about this topic can be found in the <abbr
        title="World Wide Web Consortium">W3C</abbr> Internationalization
    Activity [<a href="#W3Ci18n">W3Ci18n</a>].</p>

<h4 id="clanguage">2.1.3 Content language</h4>

<p>Because the web is a multilingual and multicultural space in which
    information can be presented in different languages, evaluation tools should
    be in the position to handle them. From an accessibility standpoint, the
    language of the content is relevant to some accessibility criteria like <a
            href="http://www.w3.org/TR/UNDERSTANDING-WCAG20/meaning-supplements.html">readability</a>.
    Therefore, the tool should explicitly declare for such criteria which
    content languages they support.</p>

<h4 id="fragments">2.1.4 <abbr>DOM</abbr> document fragments </h4>

<p>Many web sites are generated dynamically by combining code templates with
    <abbr>HTML</abbr> snippets that are created by website editors. Evaluation
    tools may be integrated into Content Management Systems (<abbr>CMS</abbr>)
    and Integrated Development Environments (<abbr>IDE</abbr>) to test these
    snippets as developers and/or editors create them.</p>

<p>Usually this is implemented in the evaluation tools by creating <a
    href="http://www.w3.org/TR/dom/#interface-documentfragment"><abbr>DOM</abbr>
    document fragments</a> [<a href="#DOM">DOM</a>] from these snippets.
    Evaluation tools may filter as well the accessibility tests according to
    their relevance to the document fragment.</p>

<p>In this case, it is also frequent that these resources are not transmitted
    via HTTP. For such cases, it is recommended to include the considerations of
    <a href="#renderedDOM" class="termref">section 2.1.5</a>.</p>

<h4 id="renderedDOM">2.1.5 Static code evaluation vs. rendered DOM
    evaluation</h4>

<p>As mentioned earlier (see <a href="#resformats" class="termref">section
    2.1.1</a>), from the accessibility standpoint it is very important to
    consider not only the static <abbr>HTML</abbr> source code of a web page,
    but how the web page is rendered with its associated resources (i.e., media,
    scripts, styles) and presented to the end user. Therefore, it is recommended
    that the evaluation process occurs on the rendered <abbr>DOM</abbr>,
    otherwise the tool will miss the complexity of the interface presented to
    the end-user. This is especially relevant for web and cloud applications,
    which are common on the web. </p>

<p>The rendering process should not be underestimated and most of times requires
    the integration of the evaluation tool with a <a
            href="http://en.wikipedia.org/wiki/Web_browser_engine">web browser
        engine</a>. This integration can be achieved in different ways (see <a
            href="#platform" class="termref">section 2.4.6</a>).</p>

<h4 id="cnegotiation">2.1.6 Content negotiation</h4>

<p>Content negotiation is a characteristic of the <abbr>HTTP(S)</abbr> protocol
    that enables web servers to customize the representation of the requested
    resources according to the demands of the client user agent. Because of
    this, the identification of resources on the web by a Uniform Resource
    Identifier (<abbr>URI</abbr>) alone may not be sufficient. From the
    accessibility perspective, this implies that a resource may present
    accessibility problems, whilst another one under the same <abbr>URI</abbr>
    may be fully accessible (for instance, when the page is requested in
    another language).</p>

<p>To support content negotiation, the testing tool customizes and stores the
    <abbr>HTTP</abbr> headers according to different criteria:</p>

<ul>
    <li>to fetch a particular variant of the content, such as a mobile website;
    </li>

    <li>to fetch a specific language version of a website;</li>

    <li>to control session and authentication information;</li>

    <li>etc.</li>
</ul>

<p>Content negotiation is supported by other elements described in the following
    like <a href="#cookies" class="termref">cookies</a>, <a
            href="#authentication" class="termref">authentication</a> and <a
            href="#session" class="termref">session information</a>.</p>

<h4 id="cookies">2.1.7 Cookies</h4>

<p>A cookie is a name-value pair that it is stored by the user-agent [<a
        href="#HTTPCOOKIES">HTTPCOOKIES</a>]. Cookies contain information
    relevant to the website that is being rendered and often include <a
            href="#authentication" class="termref">authentication</a> and <a
            href="#session" class="termref">session information</a> exchanged
    between the client and the server, which as seen before, may be relevant for
    <a href="#cnegotiation" class="termref">content negotiation</a>. A tool that
    supports cookies may store the cookie information provided by the server in
    an <abbr>HTTP</abbr> response and reuse it in subsequent requests. It may
    also allow the user to manually set cookie information to be used with the
    <abbr>HTTP</abbr> requests.</p>

<h4 id="authentication">2.1.8 Authentication</h4>

<p>Websites may require authentication (e.g., <abbr>HTTP</abbr> authentication,
    OpenID, etc.) to control access to given parts of the website or to present
    customized content to authenticated users. A tool that supports
    authentication allows the user to provide their credentials beforehand, so
    that they are used when accessing protected resources, or it prompts the
    user to enter her credentials upon the server request. The tool may also
    support the use of different credentials for different parts of a web site.
</p>

<h4 id="session">2.1.9 Session tracking</h4>

<p>Within <abbr>HTTP</abbr>, session information can be used for different
    purposes like, e.g., implementation of security mechanisms (login
    information, to logout a user after a long inactivity period) or track the
    interaction paths of the users. Session information can be stored in the
    user agent local storage, in a session ID in the <abbr>URL</abbr> or in a
    <a href="#cookies" class="termref">cookie</a>, for example. An evaluation
    tool that supports session tracking should be able to handle these different
    scenarios.</p>

<h4 id="crawling">2.1.10 Crawling</h4>

<p>Some evaluation tools incorporate a web crawler [<a href="#WEBCRAWLER">WEBCRAWLER</a>]
    able to extract hyperlinks out of web resources. There are many types of
    resources on the web that contain hyperlinks. The misconception that only
    <abbr>HTML</abbr> documents contain links may lead to wrong results in the
    evaluation process. </p>

<p>A web crawler defines an starting point and a set of options. The most common
    features of a web crawler (configuration capabilities) are:</p>
<ul>
    <li>Types of resource formats crawled (see <a href="#resformats"
            class="termref">section 2.1.1</a>).
    </li>

    <li>Capability to define inclusion and exclusion filters. Tool users may
        require analysis of concrete parts of the website or may not want to
        include others. Filters can be defined in different ways. For example,
        the user could define regular expressions against which URLs are
        matched, the maximum number resources to be crawled or a maximum
        recursion level in the crawling process.
    </li>

    <li>Multithreaded crawling. For a large site, it may be important to
        optimize performance by having a tool able to crawl in parallel threads.
    </li>

    <li>Avoidance of duplicate downloads and endless loops. Web resources may
        link to the same resource many times (for example, stylesheets, main
        navigation pages, images, etc.) in the same website. If the crawler is
        not able to identify such issues, it may lead to a great performance
        loss or to other runtime problems.
    </li>

    <li>Capabilities related to features described in previous sections such as
        the extraction of links from <a href="#renderedDOM" class="termref">dynamically
            generated content</a>, <a href="#cnegotiation" class="termref">content
            negotiation</a>, <a href="#authentication" class="termref">authentication
            support</a> or <a href="#session" class="termref">session
            tracking</a>.
    </li>
</ul>

<h4 id="sampling">2.1.11 Sampling</h4>

<p>This feature refers to the capability of an evaluation tool to select a
    subset of web pages within a website according to different criteria. These
    criteria correspond to different parameters: random selection, user access
    visits, modification dates, type of content, pages with frequent user
    interaction (such as search forms or feedback forms), manual selection by
    the evaluation tool user, etc.</p>

<p>This feature is important for manual tests in large web sites where it is
    practically impossible to carry out manual accessibility tests in all of its
    web resources.</p>

<h3 id="testcustom">2.2 Testing functionality</h3>

<p>This category includes features targeted to the configuration of the tests to
    be performed.</p>

<h4 id="filterTests">2.2.1 Selection of evaluation tests</h4>

<p>Accessibility evaluation tools may offer the possibility to select a given
    subset of evaluation tests or even a single one. A typical example could be
    performing tests to the different conformance levels (A, AA or AAA) of the
    <a href="http://www.w3.org/TR/WCAG20/">Web Content Accessibility Guidelines
        2.0</a> or selecting individual tests for a single technique or common
    failure.</p>

<p>This feature shall not be confused with the fact that some tools are focused
    on testing a single characteristic of the web page, like for example, a tool
    to test color contrast.</p>

<h4 id="manual">2.2.2 Test modes</h4>

<p>Accessibility evaluation tools carry out testing in different modes:</p>

<dl>
    <dt>Automatic</dt>
    <dd>where the test was carried out automatically by the software tool
        without any human intervention. For example, the tool could detect the
        absence of a <code>lang</code> attribute in a <code>html</code> element.
    </dd>
    <dt>Manual</dt>
    <dd>where the test was carried out by human evaluators. This includes the
        case where the evaluators are aided by instructions or guidance provided
        by software tools, but where the evaluators carried out the actual test
        procedure. For example, the tool may be unable of detecting natural
        language changes and informs the user to perform that test in the page.
    </dd>
    <dt>Semiautomatic</dt>
    <dd>where the test was partially carried out by software tools, but human
        input or judgment was still required to decide or help decide the
        outcome of the test. For example, the tool could detect an alternative
        text (<code>alt</code> attribute) for an image (<code>img</code>
        element), but it cannot judge the adequacy of the text to describe the
        image.
    </dd>
</dl>

<p>(See: <cite><a href="http://www.w3.org/TR/EARL10-Schema/#TestMode">Evaluation
    and Report Language 1.0</a></cite> [<a href="#EARL10">EARL10</a>] and <cite><a
        href="http://www.w3.org/TR/ATAG20/#def-Checking">Authoring Tool
    Accessibility Guidelines 2.0</a></cite> [<a href="#ATAG20">ATAG20</a>].)</p>

<p>Support for automatic testing varies significantly between tools.
    Evaluation tools may support their users when performing semiautomatic or
    manual tests. This support could be introduced, for example, by
    highlighting in the source code or in the rendered document the areas that
    create accessibility problems or where human intervention is needed
    to evaluate the outcome of the test.</p>

<p>Tools may keep provenance information (i.e., which part of the report was
    automatically generated by the tool and which was manually modified). Few
    accessibility requirements can be tested automatically, thus full
    accessibility <a href="#conformance" class="termref">conformance</a> can
    only be ensured by supporting evaluation tool users to carry out the tests
    in manual and semiautomatic mode.</p>

<h4 id="accReqs">2.2.3 Documenting implementation of accessibility
    requirements</h4>

<p>It is recommended that accessibility evaluation tools document which
    accessibility criteria (for instance, at the level of failures and
    techniques) are implemented, thus aggregation of results (see <a
            href="#aggregation" class="termref">section 2.3.6</a>) and
    conformance statements (see <a href="#conformance" class="termref">section
        2.3.7</a>) could be better justified.</p>

<p>This information could also indicate which of the implementations are fully
    automatic, semiautomatic or require a manual evaluation (see <a
            href="#manual" class="termref">section 2.2.2</a>).</p>

<h4 id="ownTests">2.2.4 Development of own tests and test extensions</h4>

<p> Developers and quality assurance engineers sometimes need to implement their
    own tests. For that purpose, some tools define an <abbr>API</abbr> that
    helps developers to create their own tests, which respond to internal
    demands within their organization. </p>

<h4 id="webdriver">2.2.5 User interaction and test automation</h4>

<p>When evaluating accessibility of web sites and applications, it is some
    times convenient to create scripts, which emulate user interaction (e.g.,
    activating interface components by clicking with the mouse, swiping with
    the fingers on a touch-screen or using the keyboard) that modify the
    status of the current page or load new resources.</p>

<p>There are tools that enable developers to write scripts that automate the
    emulation of application's and the end-users' behavior. There is an effort
    to standardize a common <abbr>API</abbr> for such tools. One of these
    <abbr>API</abbr>s is the W3C WebDriver <abbr>API</abbr> [<a
            href="#_WebDriver">WebDriver</a>].</p>

<h4 id="emulation">2.2.6 Emulating how people with disabilities experience the
    web</h4>

<p>More than a testing feature, this is an awareness raising component of some
    tools for its users, to emulate how people with different disabilities
    experience the web. For instance, the tool could linearize the web page to
    recreate how a screen reader could present the page content, or the tool
    could modify the page and its components' colors to emulate some color
    deficiencies.</p>

<h3 id="reporting">2.3 Reporting and monitoring</h3>

<p>This category includes features related to the ability of the tool to
    present, store, import, export and compare the testing results in different
    ways. In this document the term report must be interpreted in its widest
    sense. It could be a set of computer screens presenting different tables and
    graphics, a set of icons superimposed on top of the content displayed to the
    user indicating different types of errors/warnings, a HTML document or a
    word processor document summarizing the evaluation results, etc.</p>

<h4 id="stdRep">2.3.1 Machine-readable reporting formats</h4>

<p>These are formats normally not adequate for human consumption. They are used
    for storage purposes in a database (see <a href="#database"
        class="termref">section 2.3.3</a>) or exported so that other evaluation
    tools can parse and interpret its results. The most common reporting
    languages used are:</p>

<ul>
    <li>Evaluation and Report Language (<abbr>EARL</abbr>) 1.0 [<a
            href="#EARL10">EARL10</a>], a vocabulary designed to facilitate the
        exchange of test results between web accessibility evaluation tools in a
        vendor-neutral and platform-independent format, developed by
        <abbr title="World Wide Web Consortium">W3C</abbr>.
    </li>

    <li>Comma-Separated Values (<abbr>CSV</abbr>) formats [<a
            href="#CSV">CSV</a>, <a href="#TABDATA">TABDATA</a>].
    </li>

    <li><abbr>JSON</abbr> [<a href="#JSON">JSON</a>].</li>
</ul>

<h4 id="humanRep">2.3.2 Human-readable reports</h4>

<p>These are reports targeted to the tool users. They may be <abbr>HTML</abbr>
    or word processor documents with the test results (with tables, graphics,
    etc.) to be read out of the tool context, or they may be a set of
    application windows, which guide the tool user through the different
    evaluation results, presenting aggregated views when necessary (see
    <a href="#aggregation" class="termref">section 2.3.6</a>).</p>

<h4 id="database">2.3.3 Persistence of results</h4>

<p>The implementation of monitoring features requires that the tool has a
    persistence layer (a database, for example) where results could be stored
    and retrieved at a later stage to compare different evaluation rounds.</p>

<h4 id="import">2.3.4 Importing evaluation results</h4>

<p>There are cases where tool users want to filter, combine, or compare
    evaluation results with other tools (for instance, when tool A does not test
    a given problem, but tool B does it). The support for a common reporting
    language (see <a href="#stdRep" class="termref">section 2.3.1</a>)
    facilitates those tasks by allowing importing of information. That
    functionality also permits the integration of the evaluation tool into other
    development and testing environments.</p>

<h4 id="customReport">2.3.5 Report customization</h4>

<p>This feature allows the customization of the resulting report according to
    different criteria, such as the target audience, the type of results, the
    part of the site being analyzed, the type of content, etc. This feature may
    also allow the tool user to add additional comments in the report.</p>

<h4 id="aggregation">2.3.6 Results aggregation</h4>

<p>The presentation of evaluation results and their aggregation is influenced
    by different aspects:</p>

<ul>
    <li>the hierarchy of the accessibility recommendations with
        principles, guidelines, success criteria, techniques and failures;</li>
    <li>the structure of the page (for example, accessibility errors may be
        listed for a whole web resource or presented for concrete components
        like images, videos, tables, forms, links, etc.);</li>
    <li>the progress in time (for example, with a list of resolved, existing
        and new errors);</li>
    <li>etc.</li>
</ul>

<h4 id="conformance">2.3.7 Conformance</h4>

<p>Conformance statements are demanded by some users to quickly assess the
    status of their website. When issuing such conformance statements it is thus
    necessary to tackle the different types of accessibility techniques (i.e.,
    common failures, sufficient techniques, etc.) and aggregate results as
    described in the <a href="#aggregation" class="termref">previous
    section</a>.</p>

<p> As described in <a href="#manual" class="termref">section 2.2.2</a>, full
    accessibility compliance can only be achieved when manual testing and/or
    semiautomated checking have been implemented. </p>

<h4 id="repair">2.3.8 Error repair guidance</h4>

<p>The majority of web developers have little or no knowledge about web
    accessibility. Together with their reporting capabilities, tools may provide
    additional information to support the correction of the accessibility
    problems detected. This information may include examples, tutorials,
    screencasts, pointers to online resources, links to the <abbr
            title="World Wide Web Consortium">W3C</abbr> recommendations, etc.
    This feature may include, for example, a guided step-by-step wizard which
    guides the evaluator to correct the problems found (some user interface
    mockups can be found in the document <cite><a
    href="http://www.w3.org/TR/2013/WD-IMPLEMENTING-ATAG20-20131107/#checking-types">Implementing
        ATAG 2.0, A guide to understanding and implementing Authoring Tool
        Accessibility Guidelines 2.0</a></cite>). Automatic repair of
    accessibility problems is discouraged, as it may originate non-desirable
    side-effects.</p>

<p>If the evaluation tool is part of an <a
        href="http://www.w3.org/TR/ATAG20/#def-Authoring-Tool">authoring
    tool</a> as described in the Authoring Tool Accessibility Guidelines 2.0 [<a
        href="#ATAG20">ATAG20</a>], then it can support the authoring tool to
    meet <a href="http://www.w3.org/TR/ATAG20/#sc_b321">success criterion
    B.3.2.1</a>.</p>

<h3 id="toolUsage">2.4 Tool usage</h3>

<p>This section includes characteristics that describe the integration into the
    development and edition workflow of the user or are targeted to the
    customization of different aspects of the tool depending on its audience,
    like for instance, user interface language, user interface functionality,
    user interface accessibility, etc.</p>

<h4 id="workflow">2.4.1 Workflow integration</h4>

<p>Accessibility evaluation tools present different interfaces, which allow
    their integration into the standard development workflow of the user. The
    typical ones that can be highlighted are the following:</p>
<ul>
    <li>Plug-ins or extensions in web browsers. Tools that integrate in web
        browsers may delegate on it the retrieval and rendering of the evaluated
        web content, effectively having as test subject the content the user is
        browsing at that moment. These tools may also present the evaluation
        results on the web browser's viewport or in a separate window.
    </li>

    <li>Plug-ins for Integrated Development Environments (<abbr>IDE</abbr>s) or
        for Content Management Systems (<abbr>CMS</abbr>). Tools that integrate
        with <abbr>IDE</abbr>s extend their typical capabilities to report
        accessibility errors. The communication possibilities range from direct
        integration into the <abbr>API</abbr> of the tool to access via a <abbr>REST</abbr>
        interface, for example.
    </li>

    <li>Stand-alone tools: desktop, mobile apps, online tools, etc.</li>

    <li>Integration into bug tracking systems, where developers and experts can
        monitor and trace accessibility problems.
    </li>

    <li>etc.</li>
</ul>

<h4 id="localization">2.4.2 Localization and internationalization</h4>

<p>Localization and internationalization are important to address worldwide
    markets. Tool users may not be able to speak English and it is necessary to
    present the user interface (e.g., icons, text directionality,
    <abbr>UI</abbr> layout, units, etc.) and the reports customized to other
    languages and cultures. As pointed out earlier, more information about this
    topic can be found in the <abbr title="World Wide Web Consortium">W3C</abbr>
    Internationalization Activity [<a href="#W3Ci18n">W3Ci18n</a>] and in [<a
            href="#I18N">I18N</a>]. From the accessibility standpoint, it is
    recommended to use the <a
            href="http://www.w3.org/WAI/WCAG20/translations.html">authorized
        translations of the Web Content Accessibility Guidelines</a>.</p>

<h4 id="customAudience">2.4.3 Functionality customization to different
    audiences</h4>

<p>Typically, evaluation tools are targeted to web accessibility experts with a
    deep knowledge of the topic. However, there are also tools that allow the
    customization of the evaluation results or even the user interface
    functionality to other audiences like, for instance:</p>

<ul>
    <li>web developers with no or little knowledge of accessibility, who need
        detailed information on how to correct the problems found to implement
        appropriate solutions; or
    </li>

    <li>people commissioning web accessibility evaluations, who need an
        aggregated view of the evaluation results and tools to support the
        monitoring of their own web sites.
    </li>
</ul>
<p>The availability of such characteristics must be declared explicitly and
    presented in an adequate way to these target user groups.</p>

<h4 id="policy">2.4.4 Policy environments</h4>

<p>Although there is an international effort to harmonize web accessibility
    standards, there are still minor differences in accessibility requirements
    in different countries. The tool should specify in its documentation which
    policy environments are supported. Most of the tools are focused on the
    implementation of the Web Content Accessibility Guidelines 2.0 [<a
            href="#WCAG20">WCAG20</a>], because it is the accessibility standard
    most commonly referenced in policies worldwide. </p>

<h4 id="toolAccess">2.4.5 Tool accessibility</h4>

<p>Accessibility evaluation teams may include people with disabilities.
    Therefore, it is important that the tool itself can be used with different
    assistive technologies and it is integrated with the accessibility
    <abbr>API</abbr>s of the underlying operating system. In such cases,
    compliance with <a href="http://www.w3.org/TR/ATAG20/#part_a">part A of the
    Authoring Tool Accessibility Guidelines 2.0</a> becomes an important feature
    to support both from the perspective of the user interface of the tool and
    the access to its results.</p>

<p>When producing evaluation reports to be read outside the tool itself (for
    instance, a <abbr>HTML</abbr> report to be read in a browser), it is
    important to ensure that they follow the accessibility recommendations of
    the Web Content Accessibility Guidelines 2.0 [<a href="#WCAG20">WCAG20</a>].
</p>

<h4 id="platform">2.4.6 Platform</h4>

<p>Accessibility evaluation tools present different architectures and run on
    different platforms. Typical platform examples are: desktop applications,
    browser add-ons, distributed enterprise applications (with client- and
    server-side components), etc. Additionally, some of them include a
    persistence layer in the form of a database to enable monitoring of results.
</p>

<h2 id="profiles">3 Example profiles of evaluation tools</h2>

<p>This section presents 3 examples of accessibility evaluation tools. <strong>They
    are provided for illustration purposes and do not represent an existing
    product.</strong> In every subsection, we will highlight some of the key
    features of the tool. The table at the end of the chapter summarizes and
    complements these textual descriptions.</p>

<h3 id="plugin">3.1 Example Tool A: Browser plug-in evaluating a rendered HTML
    page</h3>

<p> Tool A is a browser plug-in, which can perform a quick automatic
    accessibility evaluation on a rendered <abbr>HTML</abbr> page. The main
    features of the tool are: </p>
<ul>
    <li>Testing of the Web Content Accessibility Guidelines 2.0 [<a href="#WCAG20">WCAG20</a>] techniques that
        can be automatically analyzed. The configuration options of the tool are
        limited to perform one of the three conformance levels of <abbr>WCAG</abbr>: A, AA or
        AAA.
    </li>

    <li>Graphical presentation of accessibility issues by means of icons that
        represent different types of problems. By selecting any of the icons,
        the user receives hints on ways to solve the error.
    </li>

    <li>The tool relies on the capabilities of the browser to support cookies,
        authentication and content negotiation, but it does not offer
        configuration capabilities for these items.
    </li>

    <li>Since the tool works directly on the browser, it is not integrated in
        the workflow of users who utilize <abbr>IDE</abbr>s in their development
        process.
    </li>

    <li>The tool allows the export of the evaluation results as an
        <abbr>EARL</abbr> report
        (serialized as <abbr>JSON</abbr>-<abbr>LD</abbr>)
        or as a <abbr>CSV</abbr> file.
    </li>
</ul>
<p><a href="#tab1">Table 1</a> presents an overview of the matching features as
    described in section 2. </p>

<h3 id="largeScale">3.2 Example Tool B: Large-scale accessibility evaluation
    tool</h3>

<p>Tool B is a large-scale accessibility evaluation tool used to analyze web
    sites with large volumes of content. The main features of the tool are: </p>
<ul>
    <li>It offers its users the possibility to crawl and evaluate complete
        web sites. It also offers the possibility to customize which parts of
        the web site are analyzed by defining or excluding different areas of
        the site to be crawled.
    </li>

    <li>Evaluation results are retained in a relational database and there is a
        dashboard to compare results at different dates. Users can select a
        subset of the crawled pages and complete the automatic and semiautomatic
        tests by inspecting the selected pages and store the results in the
        database.
    </li>

    <li>The tool analyzes <abbr>HTML</abbr>, <abbr>CSS</abbr> and JavaScript,
        being able to interpret it dynamically with a rendering engine.
    </li>

    <li>The tool supports authentication, sessions, cookies and content
        negotiation by customizing the <abbr>HTTP</abbr> headers and other
        parameters used in the crawling process.
    </li>

    <li>The tool performs autonomously the <abbr>WCAG</abbr> automatic tests.
    </li>

    <li>The reports of the tool can be exported as an <abbr>EARL</abbr> report
        (serialized as <abbr>RDF</abbr>/<abbr>XML</abbr>), as a spreadsheet and
        as a <abbr>PDF</abbr> document.
    </li>

    <li>The tool implements the corresponding interfaces to the accessibility
        <abbr>API</abbr>s of the operating system, being accessible to users
        with disabilities.
    </li>
</ul>
<p><a href="#tab1">Table 1</a> presents an overview of the matching features as
    described in section 2. </p>

<h3 id="mobile">3.3 Example Tool C: Accessibility evaluation tool for mobile
    applications</h3>

<p>Tool C is an accessibility evaluation tool for web-based mobile applications.
    The tool does not support native applications, but it provides a simulation
    environment based upon a virtual machine environment that emulates the
    accessibility <abbr>API</abbr> of some devices. The main features of the
    tool are:</p>
<ul>
    <li>The tool can emulate different user agents running on given mobile
        operating systems. Like tool A, it relies on the capabilities of the
        web rendering engine to support cookies, authentication and content
        negotiation, but it does not offer configuration capabilities for
        these items.
    </li>

    <li>It shows typical display sizes corresponding to predefined smartphones
        and tablets.
    </li>

    <li>It supports <abbr>HTML</abbr>, <abbr>CSS</abbr> and JavaScript,
        providing to the users an implementation of the Web Driver
        <abbr>API</abbr>, supporting automatic and manual evaluation.
    </li>

    <li>It detects only accessibility issues related to the implementation of
        the accessibility API of the given mobile operating systems.
    </li>
</ul>
<p><a href="#tab1">Table 1</a> presents an overview of the matching features as
    described in section 2.</p>

<h3 id="overview">3.4 Side-by-Side Comparison of the Example Tools</h3>

<p>This section presents a tabular comparison the tool features described
    previously. <strong>They are provided for illustration purposes and do not
        represent an existing product.</strong></p>

<table id="tab1">
<caption>Table 1. List of features for the example tools described in section 3.
</caption>

<tr>
    <th>Category</th>

    <th>Feature</th>

    <th>Tool A</th>

    <th>Tool B</th>

    <th>Tool C</th>
</tr>

<tr>
    <th rowspan="11"><a href="#subjects" class="termref">Retrieving and rendering web content</a></th>

    <td><a href="#resformats" class="termref">Resource formats</a></td>

    <td><abbr>HTML</abbr>, <abbr>CSS</abbr> and JavaScript</td>

    <td><abbr>HTML</abbr>, <abbr>CSS</abbr> and JavaScript</td>

    <td><abbr>HTML</abbr>, <abbr>CSS</abbr> and JavaScript</td>
</tr>

<tr>
    <td><a href="#charencoding" class="termref">Character encodings</a></td>

    <td>ISO-8859-1, UTF-8, UTF-16</td>

    <td>ISO-8859-1, UTF-8</td>

    <td>ISO-8859-1, UTF-8</td>
</tr>
<tr>
    <td><a href="#clanguage" class="termref">Content language</a></td>
    <td>any language supported by these encodings: ISO-8859-1, UTF-8, UTF-16</td>
    <td>any language supported by these encodings: ISO-8859-1, UTF-8</td>
    <td>any language supported by these encodings: ISO-8859-1, UTF-8</td>
</tr>
<tr>
    <td><a href="#fragments" class="termref">DOM Document fragments</a></td>

    <td>no</td>

    <td>no</td>

    <td>no</td>
</tr>

<tr>
    <td><a href="#renderedDOM" class="termref">Static code evaluation vs.
        rendered <abbr>DOM</abbr> evaluation</a></td>

    <td>rendered <abbr>DOM</abbr> (relies on browser capabilities)</td>

    <td>rendered <abbr>DOM</abbr> (rendering engine)</td>

    <td>rendered <abbr>DOM</abbr> (rendering engine)</td>
</tr>

<tr>
    <td><a href="#cnegotiation" class="termref">Content negotiation</a></td>

    <td>relies on browser capabilities; not configurable</td>

    <td>full support; configurable</td>

    <td>relies on browser capabilities; not configurable</td>
</tr>

<tr>
    <td><a href="#cookies" class="termref">Cookies</a></td>

    <td>relies on browser capabilities; not configurable</td>

    <td>full support; configurable</td>

    <td>relies on browser capabilities; not configurable</td>
</tr>

<tr>
    <td><a href="#authentication" class="termref">Authentication</a></td>

    <td>relies on browser capabilities; not configurable</td>

    <td>full support; configurable</td>

    <td>relies on browser capabilities; not configurable</td>
</tr>

<tr>
    <td><a href="#session" class="termref">Session tracking</a></td>

    <td>relies on browser capabilities; not configurable</td>

    <td>full support; configurable</td>

    <td>relies on browser capabilities; not configurable</td>
</tr>

<tr>
    <td><a href="#crawling" class="termref">Crawling</a></td>

    <td>no</td>

    <td>yes</td>

    <td>no</td>
</tr>

<tr>
    <td><a href="#sampling" class="termref">Sampling</a></td>

    <td>no</td>

    <td>yes</td>

    <td>no</td>
</tr>

<tr>
    <th rowspan="6"><a href="#testcustom" class="termref">Testing
        functionality</a></th>

    <td><a href="#filterTests" class="termref">Selection of evaluation tests</a></td>

    <td>no</td>

    <td>yes</td>

    <td>no</td>
</tr>

<tr>
    <td><a href="#manual" class="termref">Test modes</a></td>

    <td>only automatic</td>

    <td>all</td>

    <td>all</td>
</tr>

<tr>
    <td><a href="#accReqs" class="termref">Documenting implementation of accessibility requirements</a></td>

    <td>no</td>

    <td>yes</td>

    <td>no</td>
</tr>

<tr>
    <td><a href="#ownTests" class="termref">Development of own tests and test
        extensions</a></td>

    <td>no</td>

    <td>no</td>

    <td>no</td>
</tr>

<tr>
    <td><a href="#webdriver" class="termref">Test automation</a></td>

    <td>no</td>

    <td>no</td>

    <td>yes</td>
</tr>

<tr>
    <td><a href="#emulation" class="termref">Emulating how people with
        disabilities experience the web</a></td>

    <td>no</td>

    <td>no</td>

    <td>yes</td>
</tr>

<tr>
    <th rowspan="8"><a href="#reporting" class="termref">Reporting and
        monitoring</a></th>

    <td><a href="#stdRep" class="termref">Machine-readable reporting formats</a></td>

    <td><abbr>EARL</abbr></td>

    <td><abbr>EARL</abbr></td>

    <td>none</td>
</tr>

<tr>
    <td><a href="#humanRep" class="termref">Human-readable reports</a></td>

    <td>via <abbr>UI</abbr> icons</td>

    <td>dashboard; <abbr>HTML</abbr> report</td>

    <td>dashboard</td>
</tr>

<tr>
    <td><a href="#database" class="termref">Persistence of results</a></td>

    <td>no</td>

    <td>yes</td>

    <td>no</td>
</tr>

<tr>
    <td><a href="#import" class="termref">Importing evaluation results</a></td>

    <td><abbr>EARL</abbr></td>

    <td><abbr>EARL</abbr>, <abbr>CSV</abbr></td>

    <td>no</td>
</tr>

<tr>
    <td><a href="#customReport" class="termref">Report customization</a></td>

    <td>no</td>

    <td>comments/results added by evaluator</td>

    <td>no</td>
</tr>

<tr>
    <td><a href="#aggregation" class="termref">Results aggregation</a></td>

    <td>no</td>

    <td>yes</td>

    <td>no</td>
</tr>

<tr>
    <td><a href="#conformance" class="termref">Conformance</a></td>

    <td>no</td>

    <td>yes</td>

    <td>no</td>
</tr>

<tr>
    <td><a href="#repair" class="termref">Error repair guidance</a></td>

    <td>inline hints</td>

    <td>in report</td>

    <td>yes</td>
</tr>

<tr>
    <th rowspan="6"><a href="#toolUsage" class="termref">Tool usage</a></th>

    <td><a href="#workflow" class="termref">Workflow integration</a></td>

    <td>browser plug-in</td>

    <td>stand-alone client+server application</td>

    <td>stand-alone desktop application</td>
</tr>

<tr>
    <td><a href="#localization" class="termref">Localization and
        internationalization</a></td>

    <td>en</td>

    <td>en, de, fr, es, jp</td>

    <td>en</td>
</tr>

<tr>
    <td><a href="#customAudience" class="termref">Functionality customization
        to different audiences</a></td>

    <td>developers</td>

    <td>developers, commissioners</td>

    <td>developers</td>
</tr>

<tr>
    <td><a href="#policy" class="termref">Policy environments</a></td>

    <td><abbr>WCAG</abbr> 2.0</td>

    <td><abbr>WCAG</abbr> 2.0, Section 508 (USA), <abbr>BITV</abbr> 2.0
        (Germany)</td>

    <td><abbr>WCAG</abbr> 2.0</td>
</tr>

<tr>
    <td><a href="#toolAccess" class="termref">Tool accessibility</a></td>

    <td>not accessible</td>

    <td>accessible under Microsoft Windows</td>

    <td>not accessible</td>
</tr>

<tr>
    <td><a href="#platform" class="termref">Platform</a></td>

    <td>browser add-on</td>

    <td>distributed enterprise application with an external database</td>

    <td>desktop application</td>
</tr>
</table>

<h2 id="references">4 References</h2>

<dl>
    <dt id="ATAG20">ATAG20</dt>

    <dd>Authoring Tool Accessibility Guidelines (ATAG) 2.0. W3C Candidate
        Recommendation 7 November 2013. Jan Richards, Jeanne Spellman, Jutta
        Treviranus (editors). Available at: <a
                href="http://www.w3.org/TR/ATAG20/">http://www.w3.org/TR/ATAG20/</a>
    </dd>

    <dt id="CSS2">CSS2</dt>

    <dd>Cascading Style Sheets Level 2 Revision 1 (CSS 2.1) Specification. W3C
        Recommendation 07 June 2011. Bert Bos, Tantek Çelik, Ian Hickson, Håkon
        Wium Lie (editors). Available at: <a href="http://www.w3.org/TR/CSS2/">http://www.w3.org/TR/CSS2/</a>
    </dd>

    <dt id="CSS3">CSS3</dt>

    <dd>CSS Current Status is available at: <a
            href="http://www.w3.org/standards/techs/css">http://www.w3.org/standards/techs/css</a>
    </dd>

    <dt id="CSV">CSV</dt>

    <dd>Common Format and MIME Type for Comma-Separated Values (<abbr>CSV</abbr>)
        Files. Y. Shafranovich. Internet Engineering Task Force (IETF). Request
        for Comments: 4180, 2005. Available at: <a
                href="http://tools.ietf.org/rfc/rfc4180.txt">http://tools.ietf.org/rfc/rfc4180.txt</a>
    </dd>

    <dt id="DOM">DOM</dt>

    <dd>W3C DOM4. W3C Last Call Working Draft 04 February 2014. Anne van
        Kesteren, Aryeh Gregor, Ms2ger, Alex Russell, Robin Berjon (editors).
        Available at: <a href="http://www.w3.org/TR/dom/">http://www.w3.org/TR/dom/</a>
    </dd>

    <dt id="EARL10">EARL10</dt>

    <dd>Evaluation and Report Language (EARL) 1.0 Schema. W3C Working Draft 10
        May 2011. Shadi Abou-Zahra (editor). Available at: <a
                href="http://www.w3.org/TR/EARL10-Schema/">http://www.w3.org/TR/EARL10-Schema/</a>
    </dd>

    <dt id="ECMAScript">ECMAScript</dt>

    <dd>ECMAScript® Language Specification. Standard ECMA-262 5.1 Edition / June
        2011. Available at: <a
                href="http://www.ecma-international.org/ecma-262/5.1/">http://www.ecma-international.org/ecma-262/5.1/</a>
    </dd>

    <dt id="HTML4">HTML4</dt>

    <dd>HTML 4.01 Specification. W3C Recommendation 24 December 1999. Dave
        Raggett, Arnaud Le Hors, Ian Jacobs (editors). Available at: <a
                href="http://www.w3.org/TR/html4/">http://www.w3.org/TR/html4/</a>
    </dd>

    <dt id="HTML5">HTML5</dt>

    <dd>HTML5. A vocabulary and associated APIs for HTML and XHTML. W3C
        Candidate Recommendation 04 February 2014. Robin Berjon, Steve Faulkner,
        Travis Leithead, Erika Doyle Navara, Edward O'Connor, Silvia Pfeiffer,
        Ian Hickson (editors). Available at: <a
                href="http://www.w3.org/TR/html5/">http://www.w3.org/TR/html5/</a>
    </dd>

    <dt id="HTTPCOOKIES">HTTPCOOKIES</dt>

    <dd>HTTP State Management Mechanism. A. Barth. Internet Engineering Task
        Force (IETF). Request for Comments: 6265, 2011. Available at: <a
                href="http://tools.ietf.org/rfc/rfc6265.txt">http://tools.ietf.org/rfc/rfc6265.txt</a>
    </dd>

    <dt id="I18N">I18N</dt>

    <dd>Internationalization and localization. Wikipedia. Available at: <a
            href="http://en.wikipedia.org/wiki/Internationalization_and_localization">http://en.wikipedia.org/wiki/Internationalization_and_localization</a>
    </dd>

    <dt id="JSON">JSON</dt>

    <dd>The JSON Data Interchange Format. Standard ECMA-404 1<sup>st</sup>
        Edition / October 2013. Available at: <a
                href="http://www.ecma-international.org/publications/standards/Ecma-404.htm">http://www.ecma-international.org/publications/standards/Ecma-404.htm</a>
    </dd>

    <dt id="ODF">ODF</dt>

    <dd>Open Document Format for Office Applications (OpenDocument) Version 1.2.
        OASIS Standard 29 September 2011. Patrick Durusau, Michael Brauer
        (editors). Available at: <a
                href="http://docs.oasis-open.org/office/v1.2/OpenDocument-v1.2.html">http://docs.oasis-open.org/office/v1.2/OpenDocument-v1.2.html</a>
    </dd>

    <dt id="OOXML">OOXML</dt>

    <dd>Ecma international. TC45 - Office Open XML Formats. Ecma International.
        Available at: <a
                href="http://www.ecma-international.org/memento/TC45.htm">http://www.ecma-international.org/memento/TC45.htm</a>
    </dd>

    <dt id="PDF">PDF</dt>

    <dd>PDF Reference, sixth edition. Adobe® Portable Document Format, Version
        1.7, November 2006. Adobe Systems Incorporated. Available at: <a
                href="http://www.adobe.com/devnet/pdf/pdf_reference_archive.html">http://www.adobe.com/devnet/pdf/pdf_reference_archive.html</a>
    </dd>

    <dt id="RFC2119">RFC2119</dt>

    <dd>Key words for use in <abbr>RFC</abbr>s to Indicate Requirement Levels.
        <abbr>IETF</abbr> <abbr>RFC</abbr>, March 1997. Available at: <a
                href="http://www.ietf.org/rfc/rfc2119.txt">http://www.ietf.org/rfc/rfc2119.txt</a>
    </dd>

    <dt id="TABDATA">TABDATA</dt>

    <dd>Model for Tabular Data and Metadata on the Web. W3C First Public Working
        Draft 27 March 2014. Jeni Tennison, Gregg Kellogg (editors). Available
        at: <a href="http://www.w3.org/TR/tabular-data-model/">http://www.w3.org/TR/tabular-data-model/</a>
    </dd>

    <dt id="W3Ci18n">W3Ci18n</dt>

    <dd><abbr title="World Wide Web Consortium">W3C</abbr> Internationalization
        (I18n) Activity. Available at: <a
                href="http://www.w3.org/International/">http://www.w3.org/International/</a>
    </dd>

    <dt id="WAI-ARIA">WAI-ARIA</dt>

    <dd>Accessible Rich Internet Applications (WAI-ARIA) 1.0. W3C Recommendation
        20 March 2014. James Craig, Michael Cooper (editors). Available at: <a
                href="http://www.w3.org/TR/wai-aria/">http://www.w3.org/TR/wai-aria/</a>
    </dd>

    <dt id="WCAG20">WCAG20</dt>

    <dd>Web Content Accessibility Guidelines (WCAG) 2.0. W3C Recommendation 11
        December 2008. Ben Caldwell, Michael Cooper, Loretta Guarino Reid, Gregg
        Vanderheiden (editors). Available at: <a
                href="http://www.w3.org/TR/WCAG20/">http://www.w3.org/TR/WCAG20/</a>
    </dd>

    <dt id="WCAG20-TECHS">WCAG20-TECHS</dt>

    <dd>Techniques for WCAG 2.0. Techniques and Failures for Web Content
        Accessibility Guidelines 2.0. W3C Working Group Note 8 April 2014.
        Michael Cooper, Andrew Kirkpatrick, Joshue O Connor (editors). Available
        at: <a href="http://www.w3.org/TR/WCAG20-TECHS/">http://www.w3.org/TR/WCAG20-TECHS/</a>
    </dd>

    <dt id="WEBCRAWLER">WEBCRAWLER</dt>

    <dd>Web crawler. Wikipedia. <a
            href="http://en.wikipedia.org/wiki/Web_crawler">http://en.wikipedia.org/wiki/Web_crawler</a>
    </dd>

    <dt id="_WebDriver">WebDriver</dt>

    <dd>WebDriver. W3C Working Draft 12 March 2013. Simon Stewart, David Burns
        (editors). Available at: <a
        href="http://www.w3.org/TR/webdriver/">http://www.w3.org/TR/webdriver/</a>
    </dd>

    <dt id="XHTML10">XHTML10</dt>

    <dd>XHTML™ 1.0 The Extensible HyperText Markup Language (Second Edition).
        A Reformulation of HTML 4 in XML 1.0. W3C Recommendation 26 January
        2000, revised 1 August 2002. Available at: <a
        href="http://www.w3.org/TR/xhtml1/">http://www.w3.org/TR/xhtml1/</a>
    </dd>

    <dt id="XML10">XML10</dt>

    <dd>Extensible Markup Language (XML) 1.0 (Fifth Edition). W3C Recommendation
        26 November 2008. Tim Bray, Jean Paoli, C. M. Sperberg-McQueen,
        Eve Maler, François Yergeau (editors). Available at: <a
        href="http://www.w3.org/TR/REC-xml/">http://www.w3.org/TR/REC-xml/</a>
    </dd>

    <dt id="XML11">XML11</dt>

    <dd>Extensible Markup Language (XML) 1.1 (Second Edition). W3C
        Recommendation 16 August 2006, edited in place 29 September 2006.
        Tim Bray, Jean Paoli, C. M. Sperberg-McQueen, Eve Maler,
        François Yergeau, John Cowan (editors). Available at: <a
        href="http://www.w3.org/TR/xml11/">http://www.w3.org/TR/xml11/</a>
    </dd>
</dl>
<hr/>
<h2 id="ack">Acknowledgements</h2>

<p>The editors would like to thank the contributions from the Evaluation and
    Repair Tools Working Group (<abbr>ERT</abbr> <abbr>WG</abbr>), and
    especially from Yod Samuel Martín, Philip Ackermann, Evangelos
    Vlachogiannis, Christophe Strobbe, Emmanuelle Gutiérrez y Restrepo and
    Konstantinos Votis.</p>

<p>This publication was developed with support from the <a
        href="http://www.w3.org/WAI/ACT/">WAI-ACT</a> project, co-funded by the
    <abbr title="Information and Communication Technologies">ICT</abbr>
    initiative under the European Commission's Seventh Framework Programme.</p>
</body>
</html>
